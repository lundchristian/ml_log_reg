{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in dependencies\n",
    "import math\n",
    "import random\n",
    "\n",
    "# third-party dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a\n",
    "\n",
    "Load the SpotifyFeatures.csv file and report the number of samples (songs) as well as the number of features (song properties) in the dataset.\n",
    "\n",
    "Hint: you may use the Python module Pandas and its function\n",
    "read_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIFY_CSV: str = \"data/SpotifyFeatures.csv\"\n",
    "dataset = pd.read_csv(SPOTIFY_CSV)\n",
    "print(f\"Number of samples:  {dataset.shape[0]}\")\n",
    "print(f\"Number of features: {dataset.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b\n",
    "\n",
    "You will be working with samples from two genres namely ’Pop’ and ’Classical’.\n",
    "\n",
    "Retrieve all samples belonging to the two genres and create labels for the samples i.e: ’Pop’ = 1, ’Classical’ = 0.\n",
    "\n",
    "Report how many samples belongs to the two classes.\n",
    "\n",
    "Working with all features is not always the best solution since it increases the computational cost and some of them may be useless for the task.\n",
    "\n",
    "For this dataset you should be able to separate the two classes by using two features, namely ’liveness’ and ’loudness’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all samples where 'genre' is not equal to 'Pop' or 'Classical'\n",
    "dataset = dataset[dataset[\"genre\"].isin([\"Pop\", \"Classical\"])]\n",
    "# transform the feature column 'genre' so that 'Pop' is 1 and 'Classical' is 0\n",
    "dataset[\"genre\"] = dataset[\"genre\"].map({\"Pop\": 1, \"Classical\": 0})\n",
    "# only include features 'genre', 'liveness' and 'loudness'\n",
    "dataset = dataset.loc[:, [\"genre\", \"liveness\", \"loudness\"]]\n",
    "# the modified and filtered dataset is now stored in the dataset variable\n",
    "\n",
    "# extract and report how many samples belongs to the two classes\n",
    "print(f\"Number of pop genre samples:       {dataset[dataset['genre'] == 1].shape[0]}\")\n",
    "print(f\"Number of classical genre samples: {dataset[dataset['genre'] == 0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1c\n",
    "\n",
    "From the reduced dataset, make 2 numpy arrays.\n",
    "\n",
    "The first array will be the matrix with songs along the rows and songs’ features (\"liveness\" and \"loudness\") as columns.\n",
    "\n",
    "This will be the input of our machine learning method.\n",
    "\n",
    "The second array will the vector with the songs’ genre (labels or target we want to learn).\n",
    "\n",
    "Create a training and test set by splitting the dataset.\n",
    "\n",
    "Use an 80% 20% split between the training and test set.\n",
    "\n",
    "Split the data per class so that you keep the same class distribution in the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the pop genre\n",
    "dataset_pop = dataset[dataset[\"genre\"] == 1]\n",
    "# extract pseudo-randomly 80% to use for training\n",
    "training_pop = dataset_pop.sample(frac=0.8, random_state=random.randint(1, 100))\n",
    "# extract pseudo-randomly 20% to use for testing\n",
    "test_pop = dataset_pop.drop(training_pop.index)\n",
    "\n",
    "# extract only the classical genre\n",
    "dataset_classical = dataset[dataset[\"genre\"] == 0]\n",
    "# extract pseudo-randomly 80% to use for training\n",
    "training_classical = dataset_classical.sample(frac=0.8, random_state=random.randint(1, 100))\n",
    "# extract pseudo-randomly 20% to use for testing\n",
    "test_classical = dataset_classical.drop(training_classical.index)\n",
    "\n",
    "# merge the two training sets back together, and reset the sample index\n",
    "train_set = pd.concat([training_pop, training_classical]).reset_index(drop=True)\n",
    "# merge the two testing sets back together, and reset the sample index\n",
    "test_set = pd.concat([test_pop, test_classical]).reset_index(drop=True)\n",
    "\n",
    "# the training set and test set may now be split into two numpy arrays,\n",
    "# a vector for labels and a matrix for features for each set\n",
    "# example:\n",
    "#    labels =  np.array(<train/test>_set[\"genre\"])\n",
    "#    features =  np.array(<train/test>_set.loc[:, [\"liveness\", \"loudness\"]]))\n",
    "\n",
    "print(f\"Number of samples in data set:        {dataset.shape[0]}\")\n",
    "print(f\"80% of data set:                      {int(dataset.shape[0] * 0.8)}\")\n",
    "print(f\"20% of data set:                      {int(dataset.shape[0] * 0.2)}\")\n",
    "print(f\"Number of samples in training set:    {train_set.shape[0]}\")\n",
    "print(f\"Number of samples in test set:        {test_set.shape[0]}\")\n",
    "# time for some extra wide monitor code\n",
    "print(f\"Pop percentage of dataset:            {round(dataset[dataset['genre'] == 1].shape[0] / dataset.shape[0] * 100, 2)}\")\n",
    "print(f\"Classical percentage of dataset:      {round(dataset[dataset['genre'] == 0].shape[0] / dataset.shape[0] * 100, 2)}\")\n",
    "print(f\"Pop percentage of training set:       {round(train_set[train_set['genre'] == 1].shape[0] / train_set.shape[0] * 100, 2)}\")\n",
    "print(f\"Classical percentage of training set: {round(train_set[train_set['genre'] == 0].shape[0] / train_set.shape[0] * 100, 2)}\")\n",
    "print(f\"Pop percentage of testing set:        {round(test_set[test_set['genre'] == 1].shape[0] / test_set.shape[0] * 100, 2)}\")\n",
    "print(f\"Classical percentage of testing set:  {round(test_set[test_set['genre'] == 0].shape[0] / test_set.shape[0] * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1d - Bonus\n",
    "\n",
    "Plot the samples on the liveness vs loudness plane, with a different color for each class.\n",
    "\n",
    "From the plot, will the classification be an easy task? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size: float = 2\n",
    "transparency: float = 1\n",
    "\n",
    "# plot the liveness vs loudness plane with classical on top\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    dataset_classical[\"liveness\"],\n",
    "    dataset_classical[\"loudness\"],\n",
    "    color=\"blue\",\n",
    "    label=\"classical\",\n",
    "    alpha=transparency,\n",
    "    s=size\n",
    ")\n",
    "plt.scatter(\n",
    "    dataset_pop[\"liveness\"],\n",
    "    dataset_pop[\"loudness\"],\n",
    "    color=\"red\",\n",
    "    label=\"pop\",\n",
    "    alpha=transparency,\n",
    "    s=size\n",
    ")\n",
    "plt.xlabel(\"liveness\")\n",
    "plt.ylabel(\"loudness\")\n",
    "plt.legend()\n",
    "\n",
    "# plot the liveness vs loudness plane with pop on top\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    dataset_pop[\"liveness\"],\n",
    "    dataset_pop[\"loudness\"],\n",
    "    color=\"red\",\n",
    "    label=\"pop\",\n",
    "    alpha=transparency,\n",
    "    s=size\n",
    ")\n",
    "plt.scatter(\n",
    "    dataset_classical[\"liveness\"],\n",
    "    dataset_classical[\"loudness\"],\n",
    "    color=\"blue\",\n",
    "    label=\"classical\",\n",
    "    alpha=transparency,\n",
    "    s=size\n",
    ")\n",
    "plt.xlabel(\"liveness\")\n",
    "plt.ylabel(\"loudness\")\n",
    "plt.legend()\n",
    "\n",
    "# render the two plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2a\n",
    "\n",
    "Implement your own logistic discrimination classifier and use the training data to train the classifier.\n",
    "\n",
    "You should use stochastic gradient descent and implement it in Python.\n",
    "\n",
    "Plot the training error as a function of epochs, and report the accuracy on the training set.\n",
    "\n",
    "Try different learning rates for the gradient descent and explain what you observe for these different values.\n",
    "\n",
    "Optional, it may help the learning process if the data is shuffled (songs are fed to the classifier in random order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z: float) -> float:\n",
    "    \"\"\"transforms the prediction to a probability\n",
    "\n",
    "    Args:\n",
    "        z (float): y hat or linear prediction\n",
    "\n",
    "    Returns:\n",
    "        float: log odds\n",
    "    \"\"\"\n",
    "    return 1/(1 + pow(math.e, -z))\n",
    "\n",
    "def linear_prediction(X: np.array, w: np.array, b: float) -> np.array:\n",
    "    \"\"\"element-wise linear prediction\n",
    "\n",
    "    Args:\n",
    "        X (np.array): feature vector\n",
    "        w (np.array): weights\n",
    "        b (float): bias\n",
    "\n",
    "    Returns:\n",
    "        np.array: prediction or y\n",
    "    \"\"\"\n",
    "    return np.dot(X, w) + b\n",
    "\n",
    "def binary_cross_entropy(y: float, y_hat: float) -> float:\n",
    "    \"\"\"element-wise binary cross entropy function\n",
    "\n",
    "    note that y_hat is clipped to prevent log(0) and log(1)\n",
    "\n",
    "    Args:\n",
    "        y (float): actual label\n",
    "        y_hat (float): predicted label\n",
    "\n",
    "    Returns:\n",
    "        float: loss for one element\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15\n",
    "    y_hat = np.clip(y_hat, epsilon, 1 - epsilon)\n",
    "    return -1 * (y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "def weight_derivative(x, y, y_hat) -> float:\n",
    "    \"\"\"derived binary cross entropy function with respect to w(eights)\n",
    "\n",
    "    Args:\n",
    "        x (_type_): features or input, should usually be transposed\n",
    "        y (_type_): true label\n",
    "        y_hat (_type_): predicted label\n",
    "\n",
    "    Returns:\n",
    "        float: gradient descent of w(eights)\n",
    "    \"\"\"\n",
    "    return np.dot(x, y_hat - y)\n",
    "\n",
    "def bias_derivative(y, y_hat) -> float:\n",
    "    \"\"\"derived binary cross entropy function with respect to b(ias)\n",
    "\n",
    "    Args:\n",
    "        y (_type_): true label\n",
    "        y_hat (_type_): predicted label\n",
    "\n",
    "    Returns:\n",
    "        float: gradient descent of b(ias)\n",
    "    \"\"\"\n",
    "    return y_hat - y\n",
    "\n",
    "def overall_accuracy(x: np.array, y: np.array, w: np.array, b: float, lim: float) -> float:\n",
    "    \"\"\"calculates general accuracy for classification\n",
    "\n",
    "    Args:\n",
    "        x (np.array): features\n",
    "        y (np.array): true labels\n",
    "        w (np.array): weights\n",
    "        b (float): bias\n",
    "        lim (float): threshold for accepting a probability as 1\n",
    "\n",
    "    Returns:\n",
    "        float: overall accuracy in the range 0 to 1\n",
    "    \"\"\"\n",
    "    s: int = 0\n",
    "    n: int = x.shape[0]\n",
    "    for i in range(0, n - 1):\n",
    "        y_hat = sigmoid(linear_prediction(x[i], w, b))\n",
    "        if (1 if y_hat >= lim else 0) == y[i]:\n",
    "            s += 1\n",
    "    return s / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n: int = train_set.shape[0]\n",
    "\n",
    "# initialize bias and weights as zero\n",
    "bias: float = 0\n",
    "weights = np.zeros(2)\n",
    "\n",
    "# set number of training iterations and hyperparameters\n",
    "epochs: list[int] = [i for i in range(1, 101)]\n",
    "learning_rate: float = 0.001\n",
    "\n",
    "# setup variables for training error as a function of epochs\n",
    "loss: int = 0\n",
    "error: list[float] = []\n",
    "\n",
    "# iterate over every epoch\n",
    "for epoch in epochs:\n",
    "    # set total loss to zero every epoch\n",
    "    loss = 0\n",
    "    # shuffle the training set pseudo-randomly\n",
    "    set = train_set.sample(frac=1, random_state=random.randint(1, 100))\n",
    "    # split the shuffled training set into y and x\n",
    "    labels = np.array(set[\"genre\"])\n",
    "    features = np.array(set.loc[:, [\"liveness\", \"loudness\"]])\n",
    "    # iterate over every sample in dataset\n",
    "    for i in range(0, n):\n",
    "        # calculate linear prediction and apply the sigmoid\n",
    "        predicted = sigmoid(linear_prediction(features[i], weights, bias))\n",
    "        # accumulate loss\n",
    "        loss += binary_cross_entropy(labels[i], predicted)\n",
    "        # calculate gradient descent for the weights\n",
    "        weight_gradient = weight_derivative(features[i].T, labels[i], predicted)\n",
    "        # calculate gradient descent for the bias\n",
    "        bias_gradient = bias_derivative(labels[i], predicted)\n",
    "        # update weights and bias\n",
    "        weights = weights - learning_rate * weight_gradient\n",
    "        bias = bias - learning_rate * bias_gradient\n",
    "    # calculate error as the mean loss\n",
    "    error.append(loss / n)\n",
    "\n",
    "# calculate the overall accuracy\n",
    "accuracy: float = overall_accuracy(\n",
    "    x=np.array(train_set.loc[:, [\"liveness\", \"loudness\"]]),\n",
    "    y=np.array(train_set[\"genre\"]),\n",
    "    w=weights,\n",
    "    b=bias,\n",
    "    lim=0.5\n",
    ")\n",
    "\n",
    "# report the final characteristics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Weights:  {weights}\")\n",
    "print(f\"Bias:     {bias}\")\n",
    "print(f\"Error:    {error[-1]}\")\n",
    "\n",
    "# plot the error for each epoch to get a loss graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, error)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2b\n",
    "\n",
    "Test your trained logistic discrimination classifier using the test set.\n",
    "\n",
    "Report the accuracy on the test set.\n",
    "\n",
    "Is there a significant difference between the accuracy on the training and test set?\n",
    "\n",
    "If so what might that indicate.\n",
    "\n",
    "[Optional] Inform (or brag) about your test accuracy score on Discord.\n",
    "\n",
    "It is nice to seen how other students perform while working on the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the overall accuracy for the training set\n",
    "training_oa: float = overall_accuracy(\n",
    "    x=np.array(train_set.loc[:, [\"liveness\", \"loudness\"]]),\n",
    "    y=np.array(train_set[\"genre\"]),\n",
    "    w=weights,\n",
    "    b=bias,\n",
    "    lim=0.5\n",
    ")\n",
    "# calculate the overall accuracy for the testing set\n",
    "testing_oa: float = overall_accuracy(\n",
    "    x=np.array(test_set.loc[:, [\"liveness\", \"loudness\"]]),\n",
    "    y=np.array(test_set[\"genre\"]),\n",
    "    w=weights,\n",
    "    b=bias,\n",
    "    lim=0.5\n",
    ")\n",
    "# calculate the difference in overall accuracy\n",
    "diff_oa: float = abs(training_oa - testing_oa)\n",
    "\n",
    "# report the findings\n",
    "print(f\"Training accuracy:      {training_oa}\")\n",
    "print(f\"Testing accuracy:       {testing_oa}\")\n",
    "print(f\"Difference in accuracy: {diff_oa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2c - Bonus\n",
    "\n",
    "Extract the learned parameters from your logistic regression and use them to draw the linear line separating the data on the plot you made in question (1d).\n",
    "\n",
    "This may help you understand why your classifier is performing well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 100 evenly spaced values from min liveness to max liveness\n",
    "x_values = np.linspace(min(dataset[\"liveness\"]), max(dataset[\"liveness\"]), 100)\n",
    "# loudness as a function of liveness\n",
    "# z = w1 ​* liveness + w2 ​* loudness + b\n",
    "# =>\n",
    "# loudness = y_values = -(w0 / w1) * liveness - (bias / w1)\n",
    "y_values = -(weights[0] / weights[1]) * x_values - (bias / weights[1])\n",
    "\n",
    "# plot the liveness vs loudness plane, with label boundary\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(\n",
    "    dataset_pop[\"liveness\"],\n",
    "    dataset_pop[\"loudness\"],\n",
    "    color=\"red\",\n",
    "    label=\"pop\",\n",
    "    alpha=transparency,\n",
    "    s=size\n",
    ")\n",
    "plt.scatter(\n",
    "    dataset_classical[\"liveness\"],\n",
    "    dataset_classical[\"loudness\"],\n",
    "    color=\"blue\",\n",
    "    label=\"classical\",\n",
    "    alpha=transparency,\n",
    "    s=size\n",
    ")\n",
    "plt.plot(x_values, y_values, color=\"green\", label=\"boundary\")\n",
    "plt.xlabel(\"liveness\")\n",
    "plt.ylabel(\"loudness\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3a\n",
    "\n",
    "Using the classification results from the test set in problem 2, create a confusion matrix for the classification.\n",
    "\n",
    "Report the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(x: np.array, y: np.array, w: np.array, b: float, lim: float) -> float:\n",
    "    \"\"\"calculates the confusion matrix\n",
    "\n",
    "    Args:\n",
    "        x (np.array): features\n",
    "        y (np.array): labels\n",
    "        w (np.array): weights\n",
    "        b (float): bias\n",
    "        lim (float): threshold for accepting a probability as 1\n",
    "\n",
    "    Returns:\n",
    "        float: a 2 by 2 matrix where [[\"TP\", \"FN\"], [\"FP\", \"TN\"]]\n",
    "    \"\"\"\n",
    "    TP = 0; FP = 0; TN = 0; FN = 0\n",
    "    y_hat = np.zeros(len(y))\n",
    "    # for each input value\n",
    "    for i in range(0, len(x)):\n",
    "        # calculate the predicted label\n",
    "        probability = sigmoid(linear_prediction(x[i], w, b))\n",
    "        y_hat[i] = 1 if probability >= lim else 0\n",
    "        # actual label is positive and predicted label is positive\n",
    "        if   y[i] == 1 and y_hat[i] == 1:\n",
    "            TP += 1\n",
    "        # actual label is negative and predicted label is positive\n",
    "        elif y[i] == 0 and y_hat[i] == 1:\n",
    "            FP += 1\n",
    "        # actual label is negative and predicted label is negative\n",
    "        elif y[i] == 0 and y_hat[i] == 0:\n",
    "            TN += 1\n",
    "        # actual label is positive and predicted label is negative\n",
    "        elif y[i] == 1 and y_hat[i] == 0:\n",
    "            FN += 1\n",
    "    # build and return the confusion matrix\n",
    "    return np.array([\n",
    "        [TP, FN],\n",
    "        [FP, TN]\n",
    "    ])\n",
    "\n",
    "# calculate the confusion matrix\n",
    "cm = confusion_matrix(\n",
    "    x=np.array(test_set.loc[:, [\"liveness\", \"loudness\"]]),\n",
    "    y=np.array(test_set[\"genre\"]),\n",
    "    w=weights,\n",
    "    b=bias,\n",
    "    lim=0.5\n",
    ")\n",
    "\n",
    "# calculate and report different evaluation metrics\n",
    "print(f\"Accuracy:  {round((cm[0, 0]+ cm[1, 1]) / (cm[0, 0] + cm[1, 1] + cm[1, 0] + cm[0, 1]), 2)}\")\n",
    "print(f\"F1:        {round((2 * cm[0, 0]) / (2 * cm[0, 0] + cm[1, 0] + cm[0, 1]), 2)}\")\n",
    "print(f\"Precision: {round((cm[0, 0]) / (cm[0, 0] + cm[1, 0]), 2)}\")\n",
    "print(f\"Recall:    {round((cm[0, 0]) / (cm[0, 0] + cm[0, 1]), 2)}\")\n",
    "\n",
    "# draw a confusion matrix for better visual aid, took inspiration from\n",
    "# this link https://vitalflux.com/python-draw-confusion-matrix-matplotlib/\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "tick_marks = np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]])\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm[0])):\n",
    "        ax.text(x=j, y=i, s=f\"{tick_marks[i, j]}: {cm[i, j]}\", va=\"center\", ha=\"center\")\n",
    "plt.ylabel(\"actual label\")\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3b\n",
    "\n",
    "You should now have two evaluation metrics for the performance of the classifier on the test set; accuracy and the confusion matrix.\n",
    "\n",
    "What information does the confusion matrix give you that the accuracy score does not?\n",
    "\n",
    "NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3c - Bonus\n",
    "\n",
    "Which songs are difficult to classify?\n",
    "\n",
    "Could you suggest some Classical songs that a Pop fan would like? (a good song could influence positively the mood of the evaluator)\n",
    "\n",
    "NO CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
